{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pnewmatt/github.io/blob/master/What_gets_counted_counts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import pandas for data manipulation\n",
        "import pandas as pd\n",
        "import numpy as np # For some numerical operations if needed"
      ],
      "metadata": {
        "id": "LiyRhxEfIbiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Illustrating Concepts from \"Conceptualization of Categories\" Lecture\n",
        "\n",
        "This notebook provides simple Python and Pandas examples to illustrate key concepts\n",
        "discussed this week on how categories are conceptualized, why they matter,\n",
        "and the ethical implications of classification in data science."
      ],
      "metadata": {
        "id": "1Ou0RAF3Iqdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Why Categories? The Need for Classification in Computing ---\n",
        "print(\"--- 2. Why Categories? The Need for Classification in Computing ---\")\n",
        "\n",
        "# Boolean data\n",
        "light_switch_on = True\n",
        "is_user_logged_in = False\n",
        "print(f\"Light switch is on: {light_switch_on} (Type: {type(light_switch_on)})\")\n",
        "\n",
        "# Integer data\n",
        "age = 35\n",
        "items_in_cart = 3\n",
        "print(f\"Person's age: {age} (Type: {type(age)})\")\n",
        "print(f\"Items in cart: {items_in_cart} (Type: {type(items_in_cart)})\")\n",
        "\n",
        "# String data\n",
        "name = \"Dr. Evelyn Hayes\"\n",
        "address = \"456 Innovation Drive, Techville\"\n",
        "sentence = \"Categories enable computers to organize data.\"\n",
        "print(f\"Person's name: {name} (Type: {type(name)})\")\n",
        "print(f\"Sentence: {sentence} (Type: {type(sentence)})\")\n",
        "\n",
        "# Chaos without categories (e.g., grocery store)\n",
        "unorganized_grocery_items = [\"Milk\", \"Cereal\", \"Lightbulbs\", \"Apples\", \"Cleaning Spray\", \"Bananas\", \"Bread\", \"Shampoo\"]\n",
        "print(f\"\\nUnorganized items: {unorganized_grocery_items}\")\n",
        "\n",
        "# Organizing with categories\n",
        "organized_grocery_store = {\n",
        "    \"Dairy\": [\"Milk\"],\n",
        "    \"Pantry\": [\"Cereal\", \"Bread\"],\n",
        "    \"Produce\": [\"Apples\", \"Bananas\"],\n",
        "    \"Household\": [\"Lightbulbs\", \"Cleaning Spray\", \"Shampoo\"]\n",
        "}\n",
        "print(\"\\nOrganized Grocery Store:\")\n",
        "for category, items in organized_grocery_store.items():\n",
        "    print(f\"  {category}: {items}\")\n",
        "\n",
        "# Using Pandas for structured organization\n",
        "grocery_df_data = [\n",
        "    {\"item\": \"Milk\", \"category\": \"Dairy\", \"price\": 3.50},\n",
        "    {\"item\": \"Cereal\", \"category\": \"Pantry\", \"price\": 4.00},\n",
        "    {\"item\": \"Lightbulbs\", \"category\": \"Household\", \"price\": 8.00},\n",
        "    {\"item\": \"Apples\", \"category\": \"Produce\", \"price\": 0.75},\n",
        "    {\"item\": \"Bananas\", \"category\": \"Produce\", \"price\": 0.50}\n",
        "]\n",
        "grocery_df = pd.DataFrame(grocery_df_data)\n",
        "print(\"\\nGrocery Items in a Pandas DataFrame:\")\n",
        "print(grocery_df)\n",
        "print(f\"\\nItems in 'Produce' category:\\n{grocery_df[grocery_df['category'] == 'Produce']}\")\n",
        "print(\"\\n--- End of Section 2 ---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQJE4Ww1JCHm",
        "outputId": "5f5cd681-6e1e-494d-98b9-235ed7546a0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 2. Why Categories? The Need for Classification in Computing ---\n",
            "Light switch is on: True (Type: <class 'bool'>)\n",
            "Person's age: 35 (Type: <class 'int'>)\n",
            "Items in cart: 3 (Type: <class 'int'>)\n",
            "Person's name: Dr. Evelyn Hayes (Type: <class 'str'>)\n",
            "Sentence: Categories enable computers to organize data. (Type: <class 'str'>)\n",
            "\n",
            "Unorganized items: ['Milk', 'Cereal', 'Lightbulbs', 'Apples', 'Cleaning Spray', 'Bananas', 'Bread', 'Shampoo']\n",
            "\n",
            "Organized Grocery Store:\n",
            "  Dairy: ['Milk']\n",
            "  Pantry: ['Cereal', 'Bread']\n",
            "  Produce: ['Apples', 'Bananas']\n",
            "  Household: ['Lightbulbs', 'Cleaning Spray', 'Shampoo']\n",
            "\n",
            "Grocery Items in a Pandas DataFrame:\n",
            "         item   category  price\n",
            "0        Milk      Dairy   3.50\n",
            "1      Cereal     Pantry   4.00\n",
            "2  Lightbulbs  Household   8.00\n",
            "3      Apples    Produce   0.75\n",
            "4     Bananas    Produce   0.50\n",
            "\n",
            "Items in 'Produce' category:\n",
            "      item category  price\n",
            "3   Apples  Produce   0.75\n",
            "4  Bananas  Produce   0.50\n",
            "\n",
            "--- End of Section 2 ---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Material Consequences of Classification: Census Data Example ---\n",
        "print(\"--- 3. Material Consequences of Classification: Census Data Example ---\")\n",
        "census_data = {\n",
        "    'id': [1, 2, 3, 4, 5, 6, 7, 8],\n",
        "    'age': [34, 67, 22, 45, 58, 29, 72, 40],\n",
        "    'district': ['A', 'B', 'A', 'C', 'B', 'C', 'A', 'B'],\n",
        "    'income_bracket': ['Medium', 'High', 'Low', 'Medium', 'High', 'Low', 'Medium', 'Medium'],\n",
        "    'voted_last_election': [True, True, False, True, True, True, False, True]\n",
        "}\n",
        "census_df = pd.DataFrame(census_data)\n",
        "print(\"Mock Census Data:\")\n",
        "print(census_df)\n",
        "\n",
        "# Drawing voting districts (simplified: count per district)\n",
        "print(\"\\nPopulation count per district (could influence districting):\")\n",
        "print(census_df['district'].value_counts())\n",
        "\n",
        "# Policy decisions (e.g., resource allocation by income)\n",
        "print(\"\\nAverage age by income bracket (could inform services for seniors/youth):\")\n",
        "print(census_df.groupby('income_bracket')['age'].mean())\n",
        "\n",
        "# Budget allocation (e.g., voter outreach based on turnout)\n",
        "print(\"\\nVoter turnout by district (could inform budget for voter education):\")\n",
        "print(census_df.groupby('district')['voted_last_election'].sum() / census_df.groupby('district')['voted_last_election'].count())\n",
        "print(\"\\n--- End of Section 3 ---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6_ODahgJTEd",
        "outputId": "ab34cb8b-0957-46be-d2f8-6d8c89857914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 3. Material Consequences of Classification: Census Data Example ---\n",
            "Mock Census Data:\n",
            "   id  age district income_bracket  voted_last_election\n",
            "0   1   34        A         Medium                 True\n",
            "1   2   67        B           High                 True\n",
            "2   3   22        A            Low                False\n",
            "3   4   45        C         Medium                 True\n",
            "4   5   58        B           High                 True\n",
            "5   6   29        C            Low                 True\n",
            "6   7   72        A         Medium                False\n",
            "7   8   40        B         Medium                 True\n",
            "\n",
            "Population count per district (could influence districting):\n",
            "district\n",
            "A    3\n",
            "B    3\n",
            "C    2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Average age by income bracket (could inform services for seniors/youth):\n",
            "income_bracket\n",
            "High      62.50\n",
            "Low       25.50\n",
            "Medium    47.75\n",
            "Name: age, dtype: float64\n",
            "\n",
            "Voter turnout by district (could inform budget for voter education):\n",
            "district\n",
            "A    0.333333\n",
            "B    1.000000\n",
            "C    1.000000\n",
            "Name: voted_last_election, dtype: float64\n",
            "\n",
            "--- End of Section 3 ---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Intersectionality: Beyond Single Categories ---\n",
        "print(\"--- 4. Intersectionality: Beyond Single Categories ---\")\n",
        "intersectional_data = {\n",
        "    'id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    'race': ['White', 'Black', 'Asian', 'Hispanic', 'Black', 'White', 'Hispanic', 'Asian', 'Black', 'White'],\n",
        "    'gender': ['Woman', 'Woman', 'Man', 'Woman', 'Man', 'Man', 'Man', 'Woman', 'Woman', 'Man'],\n",
        "    'employment_status': ['Employed', 'Employed', 'Unemployed', 'Employed', 'Employed', 'Student', 'Unemployed', 'Employed', 'Student', 'Employed'],\n",
        "    'income': [60000, 65000, 20000, 55000, 70000, 15000, 22000, 75000, 12000, 80000]\n",
        "}\n",
        "intersectional_df = pd.DataFrame(intersectional_data)\n",
        "print(\"Mock Intersectional Data:\")\n",
        "print(intersectional_df)\n",
        "\n",
        "# Examining one category\n",
        "print(\"\\nAverage income by race:\")\n",
        "print(intersectional_df.groupby('race')['income'].mean())\n",
        "\n",
        "print(\"\\nAverage income by gender:\")\n",
        "print(intersectional_df.groupby('gender')['income'].mean())\n",
        "\n",
        "# Examining an intersection: Black Women\n",
        "black_women_df = intersectional_df[\n",
        "    (intersectional_df['race'] == 'Black') &\n",
        "    (intersectional_df['gender'] == 'Woman')\n",
        "]\n",
        "print(\"\\nData for Black Women:\")\n",
        "print(black_women_df)\n",
        "print(f\"Average income for Black Women: ${black_women_df['income'].mean():.2f}\")\n",
        "\n",
        "# Examining another intersection: Unemployed Hispanic Men\n",
        "unemployed_hispanic_men_df = intersectional_df[\n",
        "    (intersectional_df['race'] == 'Hispanic') &\n",
        "    (intersectional_df['gender'] == 'Man') &\n",
        "    (intersectional_df['employment_status'] == 'Unemployed')\n",
        "]\n",
        "print(\"\\nData for Unemployed Hispanic Men:\")\n",
        "print(unemployed_hispanic_men_df)\n",
        "if not unemployed_hispanic_men_df.empty:\n",
        "    print(f\"Average income for Unemployed Hispanic Men: ${unemployed_hispanic_men_df['income'].mean():.2f}\")\n",
        "else:\n",
        "    print(\"No data for Unemployed Hispanic Men in this sample.\")\n",
        "print(\"\\n--- End of Section 4 ---\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1F_c-ou0JZT5",
        "outputId": "02d88dbd-7c98-4a1f-c342-c94334363ea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 4. Intersectionality: Beyond Single Categories ---\n",
            "Mock Intersectional Data:\n",
            "   id      race gender employment_status  income\n",
            "0   1     White  Woman          Employed   60000\n",
            "1   2     Black  Woman          Employed   65000\n",
            "2   3     Asian    Man        Unemployed   20000\n",
            "3   4  Hispanic  Woman          Employed   55000\n",
            "4   5     Black    Man          Employed   70000\n",
            "5   6     White    Man           Student   15000\n",
            "6   7  Hispanic    Man        Unemployed   22000\n",
            "7   8     Asian  Woman          Employed   75000\n",
            "8   9     Black  Woman           Student   12000\n",
            "9  10     White    Man          Employed   80000\n",
            "\n",
            "Average income by race:\n",
            "race\n",
            "Asian       47500.000000\n",
            "Black       49000.000000\n",
            "Hispanic    38500.000000\n",
            "White       51666.666667\n",
            "Name: income, dtype: float64\n",
            "\n",
            "Average income by gender:\n",
            "gender\n",
            "Man      41400.0\n",
            "Woman    53400.0\n",
            "Name: income, dtype: float64\n",
            "\n",
            "Data for Black Women:\n",
            "   id   race gender employment_status  income\n",
            "1   2  Black  Woman          Employed   65000\n",
            "8   9  Black  Woman           Student   12000\n",
            "Average income for Black Women: $38500.00\n",
            "\n",
            "Data for Unemployed Hispanic Men:\n",
            "   id      race gender employment_status  income\n",
            "6   7  Hispanic    Man        Unemployed   22000\n",
            "Average income for Unemployed Hispanic Men: $22000.00\n",
            "\n",
            "--- End of Section 4 ---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Illustrating Domains from the Matrix of Domination (Conceptual Examples) ---\n",
        "print(\"--- 5. Illustrating Domains from the Matrix of Domination ---\")\n",
        "\n",
        "# Structural Domain: Absence of national paid parental leave\n",
        "# (Markdown cell explanation in Colab)\n",
        "\"\"\"\n",
        "**Structural Domain Example:**\n",
        "The lecture mentions the absence of a national law guaranteeing paid parental leave\n",
        "in the US. If we had an employment dataset, the *lack* of a column like\n",
        "'has_access_to_paid_parental_leave' or seeing this column be 'False' for most\n",
        "US-based employees would reflect this structural issue.\n",
        "This isn't directly coded as a 'law' in data, but its effects are seen in the data.\n",
        "\"\"\"\n",
        "employment_data_structural = {\n",
        "    'employee_id': [101, 102, 103, 104],\n",
        "    'country': ['US', 'Canada', 'US', 'Germany'],\n",
        "    'paid_parental_leave_weeks': [0, 52, 0, 58] # Hypothetical based on national policies\n",
        "}\n",
        "employment_structural_df = pd.DataFrame(employment_data_structural)\n",
        "print(\"Structural Domain (Paid Parental Leave Example):\")\n",
        "print(employment_structural_df)\n",
        "\n",
        "\n",
        "# Disciplinary Domain: Racial covenants\n",
        "property_applications_data = {\n",
        "    'applicant_id': [1, 2, 3, 4],\n",
        "    'applicant_race': ['White', 'Black', 'Asian', 'White'],\n",
        "    'property_has_racial_covenant': [False, True, False, False], # True if deed had historical covenant\n",
        "    'application_status': ['Pending'] * 4\n",
        "}\n",
        "property_df = pd.DataFrame(property_applications_data)\n",
        "print(\"\\nDisciplinary Domain (Racial Covenants Example - Initial):\")\n",
        "print(property_df)\n",
        "\n",
        "# Simulating a neighborhood association's disciplinary action (not a law)\n",
        "for index, row in property_df.iterrows():\n",
        "    if row['property_has_racial_covenant'] and row['applicant_race'] == 'Black':\n",
        "        property_df.loc[index, 'application_status'] = 'Rejected (Neighborhood Assoc. Rule)'\n",
        "    else:\n",
        "        property_df.loc[index, 'application_status'] = 'Approved / Further Review'\n",
        "print(\"\\nAfter Disciplinary 'Rule' Application:\")\n",
        "print(property_df)\n",
        "\n",
        "# Hegemonic Domain: Media representation\n",
        "# (Markdown cell explanation in Colab)\n",
        "\"\"\"\n",
        "**Hegemonic Domain Example:**\n",
        "The lecture mentions media representations like 'Leave It to Beaver' shaping ideas\n",
        "of a 'normal' family. This isn't directly coded but influences the data we *collect*\n",
        "or how features are *interpreted*. For example, if datasets about family structures\n",
        "historically over-represented a nuclear family, it reinforces this hegemonic ideal.\n",
        "The image search bias discussed later is another strong example of this.\n",
        "\"\"\"\n",
        "\n",
        "# Interpersonal Domain: \"Pink Tax\"\n",
        "product_data_interpersonal = {\n",
        "    'product_id': ['A1', 'A2', 'B1', 'B2'],\n",
        "    'product_type': ['Razor', 'Razor', 'Shampoo', 'Shampoo'],\n",
        "    'target_consumer': ['Men', 'Women', 'Unisex', 'Women (Floral Scent)'],\n",
        "    'base_cost': [2.0, 2.0, 3.0, 3.0],\n",
        "    'price': [5.0, 6.5, 6.0, 7.0] # Women's versions priced higher\n",
        "}\n",
        "products_interpersonal_df = pd.DataFrame(product_data_interpersonal)\n",
        "products_interpersonal_df['markup'] = (products_interpersonal_df['price'] - products_interpersonal_df['base_cost']) / products_interpersonal_df['base_cost']\n",
        "print(\"\\nInterpersonal Domain ('Pink Tax' Example):\")\n",
        "print(products_interpersonal_df)\n",
        "print(\"\\nNote the higher markup for products targeted at 'Women' for similar base items.\")\n",
        "print(\"\\n--- End of Section 5 ---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnWUkStsJmG5",
        "outputId": "b2af55a3-8a4b-4029-868b-83d39a19bb82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 5. Illustrating Domains from the Matrix of Domination ---\n",
            "Structural Domain (Paid Parental Leave Example):\n",
            "   employee_id  country  paid_parental_leave_weeks\n",
            "0          101       US                          0\n",
            "1          102   Canada                         52\n",
            "2          103       US                          0\n",
            "3          104  Germany                         58\n",
            "\n",
            "Disciplinary Domain (Racial Covenants Example - Initial):\n",
            "   applicant_id applicant_race  property_has_racial_covenant  \\\n",
            "0             1          White                         False   \n",
            "1             2          Black                          True   \n",
            "2             3          Asian                         False   \n",
            "3             4          White                         False   \n",
            "\n",
            "  application_status  \n",
            "0            Pending  \n",
            "1            Pending  \n",
            "2            Pending  \n",
            "3            Pending  \n",
            "\n",
            "After Disciplinary 'Rule' Application:\n",
            "   applicant_id applicant_race  property_has_racial_covenant  \\\n",
            "0             1          White                         False   \n",
            "1             2          Black                          True   \n",
            "2             3          Asian                         False   \n",
            "3             4          White                         False   \n",
            "\n",
            "                    application_status  \n",
            "0            Approved / Further Review  \n",
            "1  Rejected (Neighborhood Assoc. Rule)  \n",
            "2            Approved / Further Review  \n",
            "3            Approved / Further Review  \n",
            "\n",
            "Interpersonal Domain ('Pink Tax' Example):\n",
            "  product_id product_type       target_consumer  base_cost  price    markup\n",
            "0         A1        Razor                   Men        2.0    5.0  1.500000\n",
            "1         A2        Razor                 Women        2.0    6.5  2.250000\n",
            "2         B1      Shampoo                Unisex        3.0    6.0  1.000000\n",
            "3         B2      Shampoo  Women (Floral Scent)        3.0    7.0  1.333333\n",
            "\n",
            "Note the higher markup for products targeted at 'Women' for similar base items.\n",
            "\n",
            "--- End of Section 5 ---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Missing Data: The Library of Missing Datasets Concept ---\n",
        "print(\"--- 6. Missing Data: The Library of Missing Datasets Concept ---\")\n",
        "# Example: University Faculty Satisfaction Survey Data\n",
        "faculty_satisfaction_data = {\n",
        "    'faculty_id': [201, 202, 203, 204, 205],\n",
        "    'department': ['CS', 'History', 'CS', 'Biology', 'History'],\n",
        "    'tenured': [True, True, False, True, False],\n",
        "    'satisfaction_score (1-5)': [4, 5, 3, 4, 2],\n",
        "    'years_at_university': [10, 15, 2, 8, 3]\n",
        "}\n",
        "faculty_df = pd.DataFrame(faculty_satisfaction_data)\n",
        "print(\"Collected Data: Faculty Satisfaction Survey\")\n",
        "print(faculty_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIv6AJqPJfp_",
        "outputId": "8b40a085-bbbf-46c8-d24b-fd4032d8c784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 6. Missing Data: The Library of Missing Datasets Concept ---\n",
            "Collected Data: Faculty Satisfaction Survey\n",
            "   faculty_id department  tenured  satisfaction_score (1-5)  \\\n",
            "0         201         CS     True                         4   \n",
            "1         202    History     True                         5   \n",
            "2         203         CS    False                         3   \n",
            "3         204    Biology     True                         4   \n",
            "4         205    History    False                         2   \n",
            "\n",
            "   years_at_university  \n",
            "0                   10  \n",
            "1                   15  \n",
            "2                    2  \n",
            "3                    8  \n",
            "4                    3  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Missing Datasets (Inspired by Mimi Onuoha):**\n",
        "The collected data above gives some insights, but what's missing?\n",
        "Following Mimi Onuoha's concept, we can imagine 'empty folders' for datasets like:\n",
        "\n",
        "* 'Reasons_for_faculty_of_color_leaving_tenure_track_positions_globally'\n",
        "* 'Incidents_of_microaggressions_reported_by_non_tenured_faculty_by_department'\n",
        "* 'Salary_discrepancies_for_equivalent_roles_adjusted_for_years_experience_race_gender'\n",
        "* As the lecture mentioned: 'Police_killings_North_Carolina' or 'Femicides_US_Mexico_border'\n",
        "\n",
        "**Childbirth Mobility Example:**\n",
        "Imagine older health datasets:"
      ],
      "metadata": {
        "id": "6TArF3xjKDk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "old_health_data = {\n",
        "    'patient_id': [1,2,3],\n",
        "    'birth_year_of_mother': [1950, 1951, 1950],\n",
        "    'child_health_outcome': ['Good', 'Fair', 'Good'],\n",
        "    # 'maternal_morbidity_during_childbirth': MISSING!\n",
        "}\n",
        "old_health_df = pd.DataFrame(old_health_data)\n",
        "print(\"\\nExample: Older Health Data (Missing Maternal Morbidity)\")\n",
        "print(old_health_df)\n",
        "print(\"The absence of 'maternal_morbidity_during_childbirth' makes that form of suffering invisible in this dataset.\")\n",
        "print(\"\\n--- End of Section 6 ---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6_ZNdTFKEoh",
        "outputId": "2b09cacc-ea1f-4bfc-82c8-3f882f9992e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Example: Older Health Data (Missing Maternal Morbidity)\n",
            "   patient_id  birth_year_of_mother child_health_outcome\n",
            "0           1                  1950                 Good\n",
            "1           2                  1951                 Fair\n",
            "2           3                  1950                 Good\n",
            "The absence of 'maternal_morbidity_during_childbirth' makes that form of suffering invisible in this dataset.\n",
            "\n",
            "--- End of Section 6 ---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. Risks of Data Collection: De-anonymization in Small Groups ---\n",
        "print(\"--- 7. Risks of Data Collection: De-anonymization in Small Groups ---\")\n",
        "# \"Anonymized\" university faculty data (names removed)\n",
        "anonymized_faculty_data = {\n",
        "    # 'name': ['Removed'],\n",
        "    'department': ['Physics', 'Physics', 'History', 'Art', 'Physics', 'Art', 'History'],\n",
        "    'tenure_status': ['Tenured', 'Tenured', 'Tenured', 'Associate', 'Tenured', 'Associate', 'Tenured'],\n",
        "    'research_area': ['Quantum Computing', 'Astrophysics', 'Medieval Europe', 'Sculpture', 'Particle Physics', 'Digital Art', 'Renaissance Italy'],\n",
        "    'underrepresented_group_status': [False, False, False, True, False, True, False] # Simplified\n",
        "}\n",
        "anon_faculty_df = pd.DataFrame(anonymized_faculty_data)\n",
        "print(\"Hypothetical 'Anonymized' Faculty Data:\")\n",
        "print(anon_faculty_df)\n",
        "\n",
        "# Attempt to identify an individual from an underrepresented group\n",
        "# Suppose we know there's only one tenured faculty in Art from an underrepresented group\n",
        "potential_identification = anon_faculty_df[\n",
        "    (anon_faculty_df['department'] == 'Art') &\n",
        "    (anon_faculty_df['tenure_status'] == 'Associate') & # Corrected from lecture example for this dataset\n",
        "    (anon_faculty_df['underrepresented_group_status'] == True)\n",
        "]\n",
        "print(\"\\nSearching for: Art department, Associate Professor, Underrepresented Group\")\n",
        "print(potential_identification)\n",
        "if len(potential_identification) == 1:\n",
        "    print(\"Result: A single individual matches. Privacy is compromised despite 'anonymization'.\")\n",
        "elif len(potential_identification) > 1:\n",
        "    print(\"Result: Multiple individuals match. Identification is harder but still a risk with more data.\")\n",
        "else:\n",
        "    print(\"Result: No individuals match this specific query.\")\n",
        "\n",
        "# The lecture mentions tenured faculty, if the \"Art\" department only had one tenured faculty\n",
        "# and that person was from an underrepresented group, they'd be identifiable.\n",
        "# Let's adjust for a scenario where the risk is clearer:\n",
        "# What if there's only ONE person in 'Physics' focusing on 'Quantum Computing' and they are 'Tenured'?\n",
        "# If that person is also from an underrepresented group (even if that data wasn't explicitly linked initially),\n",
        "# external knowledge could bridge the gap.\n",
        "\n",
        "potential_identification_physics = anon_faculty_df[\n",
        "    (anon_faculty_df['department'] == 'Physics') &\n",
        "    (anon_faculty_df['research_area'] == 'Quantum Computing') &\n",
        "    (anon_faculty_df['tenure_status'] == 'Tenured')\n",
        "]\n",
        "print(\"\\nSearching for: Physics, Quantum Computing, Tenured\")\n",
        "print(potential_identification_physics)\n",
        "if len(potential_identification_physics) == 1:\n",
        "    print(\"Result: A single individual matches based on department, research area and tenure. If this person is known to be from an underrepresented group, their specific record here is identified.\")\n",
        "\n",
        "print(\"\\n--- End of Section 7 ---\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMfJJqDRKRzZ",
        "outputId": "e664d517-8928-4f5e-fde1-a765d97d08b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 7. Risks of Data Collection: De-anonymization in Small Groups ---\n",
            "Hypothetical 'Anonymized' Faculty Data:\n",
            "  department tenure_status      research_area  underrepresented_group_status\n",
            "0    Physics       Tenured  Quantum Computing                          False\n",
            "1    Physics       Tenured       Astrophysics                          False\n",
            "2    History       Tenured    Medieval Europe                          False\n",
            "3        Art     Associate          Sculpture                           True\n",
            "4    Physics       Tenured   Particle Physics                          False\n",
            "5        Art     Associate        Digital Art                           True\n",
            "6    History       Tenured  Renaissance Italy                          False\n",
            "\n",
            "Searching for: Art department, Associate Professor, Underrepresented Group\n",
            "  department tenure_status research_area  underrepresented_group_status\n",
            "3        Art     Associate     Sculpture                           True\n",
            "5        Art     Associate   Digital Art                           True\n",
            "Result: Multiple individuals match. Identification is harder but still a risk with more data.\n",
            "\n",
            "Searching for: Physics, Quantum Computing, Tenured\n",
            "  department tenure_status      research_area  underrepresented_group_status\n",
            "0    Physics       Tenured  Quantum Computing                          False\n",
            "Result: A single individual matches based on department, research area and tenure. If this person is known to be from an underrepresented group, their specific record here is identified.\n",
            "\n",
            "--- End of Section 7 ---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 8. Implicit Bias in Language & Data: Algorithmic Bias Simulation ---\n",
        "print(\"--- 8. Implicit Bias in Language & Data: Algorithmic Bias Simulation ---\")\n",
        "# (Markdown cell explanation in Colab for \"Banana\" example)\n",
        "\"\"\"\n",
        "**Implicit Bias in Language: The \"Banana\" Example**\n",
        "As the lecture states:\n",
        "> Consider that people say \"green bananas,\" but people never say, \"hand me a yellow banana.\"\n",
        "This implies that \"yellow\" is the default, unstated assumption for a banana.\n",
        "This matters in data labeling and model training. If all training images of bananas\n",
        "are yellow and unlabeled for color, the model assumes 'banana = yellow banana'.\n",
        "It might then misclassify or struggle with green or red bananas unless explicitly trained.\n",
        "\"\"\"\n",
        "\n",
        "# Simulating Algorithmic Bias (like biased image search results)\n",
        "# We'll create \"profiles\" or \"image descriptors\" that a system might pull from.\n",
        "# These are intentionally biased to mimic the lecture's image search examples.\n",
        "\n",
        "# Computer Engineer\n",
        "# Lecture: \"overwhelmingly computers themselves or men\"\n",
        "computer_engineer_profiles = [\n",
        "    {\"primary_tag\": \"male\", \"secondary_tags\": [\"circuits\", \"code\", \"server\"]},\n",
        "    {\"primary_tag\": \"technology\", \"secondary_tags\": [\"laptop\", \"network\"]},\n",
        "    {\"primary_tag\": \"male\", \"secondary_tags\": [\"coding\", \"desk\", \"glasses\"]},\n",
        "    {\"primary_tag\": \"male\", \"secondary_tags\": [\"software\", \"system\"]},\n",
        "    {\"primary_tag\": \"female\", \"secondary_tags\": [\"collaboration\", \"whiteboard\", \"code\"]} # Few female representations\n",
        "]\n",
        "ce_df = pd.DataFrame(computer_engineer_profiles)\n",
        "print(\"\\nSimulated 'Computer Engineer' Profiles/Image Descriptors:\")\n",
        "print(ce_df['primary_tag'].value_counts())\n",
        "\n",
        "# House Cleaner\n",
        "# Lecture: \"all of the images procured for me are of women... race intersects with gender\"\n",
        "house_cleaner_profiles = [\n",
        "    {\"primary_tag\": \"female\", \"secondary_tags\": [\"cleaning supplies\", \"home\", \"apron\"], \"race_hint\": \"Hispanic/Latina\"},\n",
        "    {\"primary_tag\": \"female\", \"secondary_tags\": [\"vacuum\", \"kitchen\", \"smiling\"], \"race_hint\": \"White\"},\n",
        "    {\"primary_tag\": \"female\", \"secondary_tags\": [\"gloves\", \"spray bottle\", \"bathroom\"], \"race_hint\": \"Black\"},\n",
        "    {\"primary_tag\": \"female\", \"secondary_tags\": [\"mop\", \"bucket\", \"window\"], \"race_hint\": \"Asian\"},\n",
        "    {\"primary_tag\": \"female\", \"secondary_tags\": [\"dusting\", \"living_room\"], \"race_hint\": \"Hispanic/Latina\"}\n",
        "]\n",
        "hc_df = pd.DataFrame(house_cleaner_profiles)\n",
        "print(\"\\nSimulated 'House Cleaner' Profiles/Image Descriptors:\")\n",
        "print(hc_df['primary_tag'].value_counts())\n",
        "print(hc_df['race_hint'].value_counts())\n",
        "\n",
        "\n",
        "# Lawyer\n",
        "# Lecture: \"not necessarily gendered or racialized, but we can see how these tools...reproduce these biases\"\n",
        "lawyer_profiles = [\n",
        "    {\"primary_tag\": \"male\", \"secondary_tags\": [\"suit\", \"courtroom\", \"briefcase\"], \"race_hint\": \"White\"},\n",
        "    {\"primary_tag\": \"male\", \"secondary_tags\": [\"books\", \"desk\", \"confident\"], \"race_hint\": \"White\"},\n",
        "    {\"primary_tag\": \"female\", \"secondary_tags\": [\"office\", \"client\", \"focused\"], \"race_hint\": \"White\"}, # Fewer female\n",
        "    {\"primary_tag\": \"male\", \"secondary_tags\": [\"gavel\", \"law firm\", \"serious\"], \"race_hint\": \"White\"},\n",
        "    {\"primary_tag\": \"male\", \"secondary_tags\": [\"negotiation\", \"documents\"], \"race_hint\": \"Black\"} # Few non-white\n",
        "]\n",
        "lawyer_df = pd.DataFrame(lawyer_profiles)\n",
        "print(\"\\nSimulated 'Lawyer' Profiles/Image Descriptors:\")\n",
        "print(lawyer_df['primary_tag'].value_counts())\n",
        "print(lawyer_df['race_hint'].value_counts())\n",
        "\n",
        "# Teacher\n",
        "# Lecture: \"teacher is not gendered, but perhaps I would have had to put in 'male teacher'\"\n",
        "teacher_profiles = [\n",
        "    {\"primary_tag\": \"female\", \"secondary_tags\": [\"classroom\", \"children\", \"books\"]},\n",
        "    {\"primary_tag\": \"female\", \"secondary_tags\": [\"whiteboard\", \"students\", \"apple\"]},\n",
        "    {\"primary_tag\": \"female\", \"secondary_tags\": [\"elementary\", \"caring\", \"lesson_plan\"]},\n",
        "    {\"primary_tag\": \"female\", \"secondary_tags\": [\"high_school\", \"grading\", \"patient\"]},\n",
        "    {\"primary_tag\": \"male\", \"secondary_tags\": [\"university\", \"lecture\", \"focused\"]} # Fewer male, often different context\n",
        "]\n",
        "teacher_df = pd.DataFrame(teacher_profiles)\n",
        "print(\"\\nSimulated 'Teacher' Profiles/Image Descriptors:\")\n",
        "print(teacher_df['primary_tag'].value_counts())\n",
        "\n",
        "print(\"\\nThese skewed 'profiles' would lead an algorithm to reproduce societal biases,\")\n",
        "print(\"similar to the image search results shown in the lecture.\")\n",
        "print(\"\\n--- End of Section 8 ---\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0NeLfyGKZvl",
        "outputId": "c5127e3a-7860-4aba-d7ac-5ab0efd590c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 8. Implicit Bias in Language & Data: Algorithmic Bias Simulation ---\n",
            "\n",
            "Simulated 'Computer Engineer' Profiles/Image Descriptors:\n",
            "primary_tag\n",
            "male          3\n",
            "technology    1\n",
            "female        1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Simulated 'House Cleaner' Profiles/Image Descriptors:\n",
            "primary_tag\n",
            "female    5\n",
            "Name: count, dtype: int64\n",
            "race_hint\n",
            "Hispanic/Latina    2\n",
            "White              1\n",
            "Black              1\n",
            "Asian              1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Simulated 'Lawyer' Profiles/Image Descriptors:\n",
            "primary_tag\n",
            "male      4\n",
            "female    1\n",
            "Name: count, dtype: int64\n",
            "race_hint\n",
            "White    4\n",
            "Black    1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Simulated 'Teacher' Profiles/Image Descriptors:\n",
            "primary_tag\n",
            "female    4\n",
            "male      1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "These skewed 'profiles' would lead an algorithm to reproduce societal biases,\n",
            "similar to the image search results shown in the lecture.\n",
            "\n",
            "--- End of Section 8 ---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Double-Edged Sword (Mimi Onuoha):**\n",
        "\n",
        "As the lecture highlights, quoting Mimi Onuoha:\n",
        "> \"Black and Brown Americans face a double-edged sword. Rarely is data collected\n",
        "> that meaningfully impacts their lives... But you also see how the inclusion of\n",
        "> persons might increase surveillance.\"\n",
        "\n",
        "This section is more conceptual but vital for data scientists:\n",
        "\n",
        "* **Lack of Beneficial Data:**\n",
        "    * Example from lecture: Data on how criminal records exclude people from public housing.\n",
        "    * The *absence* of such data makes it hard to advocate for change or quantify the problem.\n",
        "\n",
        "* **Increased Surveillance/Risk with Inclusion:**\n",
        "    * Example from lecture: Including undocumented immigrants on the census.\n",
        "    * Example: Stingray phone trackers used by police departments.\n",
        "    * The very act of collecting data, even with good intentions, can create\n",
        "        vulnerabilities for the populations being studied if not handled with\n",
        "        extreme care, consent, and an understanding of the terms of inclusion.\n",
        "\n",
        "Data scientists must constantly weigh the potential benefits of data collection\n",
        "against the potential harms, especially for minoritized and vulnerable groups.\n",
        "Consent, transparency, and data minimization are key principles."
      ],
      "metadata": {
        "id": "xyMKrJwLKsan"
      }
    }
  ]
}